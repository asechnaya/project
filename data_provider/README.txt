Переделал parser. Исправил ошибки, убрал ненужное, временно объединил в один скрипт raw_data_provider и parser, запустив raw_data_provider в отдельном потоке. Добавил указание сервера и порта imap в конфиг файл.

Реализовал примитивное api в модуле api.py:
	http://127.0.0.1:5000/api (GET):
		 Возвращает UID (0) для получения писем, пришедших после этого UID.
	http://127.0.0.1:5000/api (POST):
		 Принимает на вход json со списком писем (каждое из них - словарь).

Чтобы попробовать, потребуется:
1. Модули pip (в requirements.txt):
	pyzmq
	msgpack
	Flask
	requests

2. Модуль "imap_credentials.py":
	Этот файл добавлен в .gitignore, чтобы случайно не залить в репу свои логин и пароль от почты.
	Внутри должны быть строки:
		imap_username = ''
		imap_password = ''
		imap_server = '' # Например, 'imap.gmail.com'
		imap_port = 993 # Или другой порт, без кавычек, т.к. int
	Внутри одинарных ковычек логин, пароль и сервер соответственно.

Далее запускаете api.py, затем parser.py. При этом:
1. В терминале с api.py можно будет наблюдать список тем и вложений
пришедших писем.
2. В терминале с parser.py можно будет наблюдать сообщения
про связь с сервером api.py и результатами опроса imap сервера.

Таким образом parser.py полностью готов для использования с
api django, надо будет только поменять URL в начале файла
"new_parser.py" на URL django, когда там будет реализовано api.








Содержание предыдущего README.txt ниже для истории:


На прошлой встрече создали черновой дизайн приложения. Передо мной стояло 2 задачи:
	№15 "Вынести отправитель и парсер в отдельные модули"
	№17 "Очередь сделать для взаимодействия сервера и парсера"

Приступив к выполнению, пришёл к выводу, что требуется очередное изменение структуры приложения:
В сравнении с предыдущей схемой(https://github.com/pavelvizir/project/blob/master/doc/%D1%81%D1%85%D0%B5%D0%BC%D0%B0.png):
	изменились связи 1, 2, 3, 4;
	совмещены очередь и парсер;
	таблица raw_data заменяется на data_providers.

Новая схема - https://github.com/pavelvizir/project/blob/new_data_provider/doc/%D1%81%D1%85%D0%B5%D0%BC%D0%B0_1.01.png

Создана ветка "new_data_provider". 
В ней 2 модуля:
	"raw_data_provider.py" (поставщик),
	"parser.py" (парсер и сервер очереди).

Для работы этих модулей понадобятся:
	НЕ ПИТОНОВСКАЯ библиотека zeromq - это очередь сообщений, через которую общаются модули,
	pyzmq (pip install pyzmq) - питоновские биндинги к zeromq,
	файл "imap_credentials.py" рядом с собой - файл с логином и паролям до gmail почтового ящика.

Про "imap_credentials.py":
	Этот файл добавлен в .gitignore, чтобы случайно не залить в репу свои логин и пароль от почты.
	Внутри должны быть 2 строки:
		imap_username = ''
		imap_password = ''
	Внутри одинарных ковычек логин и пароль соответственно.

Дальнейшие шаги:
	Требуется создание таблиц "data", "data_providers" в базе.
	Требуется создание API в Django для общения с parser. Пока только 2 вида запросов предполагаются:
		Запрос номера последнего запрошенного письма из таблицы data_providers (см. ниже пункты 1.2, 2.2);
		Помещение распарсенного письма в таблицу "data" (см. ниже пункт 2.3).
		Оба этих запроса будут прилетать в json.
	Требуется нормально оформить raw_data_provider.py и parser.py. 

Детали работы:
1. "raw_data_provider":
	Пишет сообщения в терминал, откуда запущен. Себя называет "Slave". 
	После запуска пытается связаться с сервером очереди parser.py, называя его "Master".
	Если не может связаться с Master'ом, то продолжает попытки бесконечно,
	раз в 7.5 секунд пытаясь пересоздать соединение.
	Каждая "фраза" в общении Master и Slave представляет собой json, пересылаемый по tcp с помощью zeromq.
	Если связь появляется, то:
		1. Представляется Master'у.
		2. Просит UID последнего скачанного письма.
			[ Этот UID будет браться из таблицы "data_providers" из поля "last_number", когда у нас будут эта таблица в базе и API для общения "parser.py" и сервера "django" ]
			Пока же Master просто передаёт ноль в ответ, а Slave пытается выкачать последние 10 писем.
		3. Выкачивает письма (в сыром виде, максимум 10 штук), передаёт их Master'у последовательно.
		4. После передачи всех скачанных писем начинает проверку новых писем ещё раз. Если:
			- новых писем нет, то говорит об этом Master'у и засыпает на 10 секунд.
			- если есть, то повторяет пункт 3.

	И так бесконечно, пока не прервать его работу. На любом этапе, если связь с Master'ом пропадает, то пытается переслать последнее сообщение.

2. "parser":
	Пишет сообщения в терминал, откуда запущен. Себя называет "Master". 
	После запуска ждёт подключений от raw_data_provider.py, называя его "Slave".
	Каждая "фраза" в общении Master и Slave представляет собой json, пересылаемый по tcp с помощью zeromq.
	Если подключение появляется, то:
		1. Общается со Slave'ом.
		2. Даёт UID последнего скачанного письма после запроса.
			[ Этот UID будет браться из таблицы "data_providers" из поля "last_number", когда у нас будут эта таблица в базе и API для общения "parser.py" и сервера "django" ]
			Пока же Master просто передаёт ноль в ответ, а Slave пытается выкачать последние 10 писем.
		3. Получает письма (в сыром виде) по одному. Обрабатыает их (парсит).
			[ Эти письма он будет передавать в таблицу "data", когда у нас будет эта таблица в базе и API для общения "parser.py" и сервера "django" ]
			Пока же Master просто выводит в терминал тему письма.
		4. Ожидает дальнейших сообщений от Slave. Сообщения могут быть:
			- с новым письмом, тогда Master повторяет пункт 3.
			- либо "Новых писем нет".

	И так бесконечно, пока не прервать его работу. На любом этапе, если связь с Slave'ом пропадает, то Master просто ждёт.

	Slave может быть много. Можно попробовать запустить несколько Slave. Работать будет, но не очень правильно, так как пока ещё не получаются из базы последний UID, т.е. каждый Slave попытается скачать последние 10 писем из ящика в начале работы. Такое поведение задумано, так как эти модули не хранят состояние между запусками, а должны получать его от основного сервера приложения.
